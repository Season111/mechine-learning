{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试mindspore版本\n",
    "import mindspore\n",
    "print(mindspore.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试gpu是否可用\n",
    "import numpy as np\n",
    "from mindspore import Tensor\n",
    "from mindspore.ops import functional as F\n",
    "import mindspore.context as context\n",
    "\n",
    "context.set_context(device_target=\"GPU\")\n",
    "x = Tensor(np.ones([1,3,3,4]).astype(np.float32))\n",
    "y = Tensor(np.ones([1,3,3,4]).astype(np.float32))\n",
    "print(F.tensor_add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用mindspore构造平方损失函数\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor\n",
    "y_pred = Tensor([1, 2, 3, 4])\n",
    "y_true = Tensor([1, 1, 1, 1])\n",
    "\n",
    "def square_loss(y_pred, y_true):\n",
    "    return (y_pred - y_true) ** 2\n",
    "print(square_loss(y_pred, y_true))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用mindspore实现一维线性回归\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor\n",
    "#实现一维线性回归\n",
    "class LinearRegression(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.weight = Tensor(np.random.randn(1), mindspore.float32)\n",
    "        self.bias = Tensor(np.random.randn(1), mindspore.float32)\n",
    "    def construct(self, x):\n",
    "        return self.weight * x + self.bias\n",
    "#测试\n",
    "linear_regression = LinearRegression()\n",
    "print(linear_regression(Tensor(1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现随机梯度下降算法\n",
    "class SGD(nn.Cell):\n",
    "    def __init__(self, learning_rate):\n",
    "        super(SGD, self).__init__()\n",
    "        self.learning_rate = Tensor(learning_rate, mindspore.float32)\n",
    "    def construct(self, weight, bias, dw, db):\n",
    "        weight = weight - self.learning_rate * dw\n",
    "        bias = bias - self.learning_rate * db\n",
    "        return weight, bias\n",
    "#测试\n",
    "sgd = SGD(0.01)\n",
    "print(sgd(Tensor(1.0), Tensor(1.0), Tensor(1.0), Tensor(1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现二分类损失函数\n",
    "class BinaryCrossEntropy(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(BinaryCrossEntropy, self).__init__()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "    def construct(self, y_pred, y_true):\n",
    "        y_pred = self.sigmoid(y_pred)\n",
    "        return self.bce_loss(y_pred, y_true)\n",
    "#测试\n",
    "bce = BinaryCrossEntropy()\n",
    "print(bce(Tensor(1.0), Tensor(1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建Min Pooling层\n",
    "class MinPooling(nn.Cell):\n",
    "    def __init__(self, kernel_size, stride, padding):\n",
    "        super(MinPooling, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "    def construct(self, x):\n",
    "        return F.min_pool(x, self.kernel_size, self.stride, self.padding)\n",
    "#测试\n",
    "min_pooling = MinPooling(2, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor\n",
    "import numpy as np\n",
    "#构造VGG网络\n",
    "class VGG(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, pad_mode=\"same\")\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, pad_mode=\"same\")\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, pad_mode=\"same\")\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, pad_mode=\"same\")\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, pad_mode=\"same\")\n",
    "        self.conv6 = nn.Conv2d(256, 256, 3, pad_mode=\"same\")\n",
    "        self.conv7 = nn.Conv2d(256, 256, 3, pad_mode=\"same\")\n",
    "        self.max_pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv8 = nn.Conv2d(256, 512, 3, pad_mode=\"same\")\n",
    "        self.conv9 = nn.Conv2d(512, 512, 3, pad_mode=\"same\")\n",
    "        self.conv10 = nn.Conv2d(512, 512, 3, pad_mode=\"same\")\n",
    "        self.max_pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv11 = nn.Conv2d(512, 512, 3, pad_mode=\"same\")\n",
    "        self.conv12 = nn.Conv2d(512, 512, 3, pad_mode=\"same\")\n",
    "        self.conv13 = nn.Conv2d(512, 512, 3, pad_mode=\"same\")\n",
    "        self.max_pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(25088, 4096)\n",
    "        self.fc2 = nn.Dense(4096, 4096)\n",
    "        self.fc3 = nn.Dense(4096, 1000)\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.max_pool3(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.max_pool4(x)\n",
    "        x = self.conv11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.conv13(x)\n",
    "        x = self.max_pool5(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "#测试\n",
    "vgg = VGG()\n",
    "print(vgg(Tensor(np.random.randn(1, 3, 224, 224), mindspore.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现强化学习示例\n",
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor\n",
    "import numpy as np\n",
    "#构造网络\n",
    "class Net(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Dense(4, 10)\n",
    "        self.fc2 = nn.Dense(10, 2)\n",
    "    def construct(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "#测试\n",
    "net = Net()\n",
    "print(net(Tensor(np.random.randn(1, 4), mindspore.float32)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd66c1ceb77ed659473192727f2f130f488a1b3f89f93f2a4194650289467c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
