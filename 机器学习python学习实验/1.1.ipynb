{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mindspore.dataset\n",
    "\n",
    "import mindspore.dataset as ds # 数据集的载入\n",
    "\n",
    "import mindspore.dataset.transforms.c_transforms as C # 常用转化算子\n",
    "\n",
    "import mindspore.dataset.vision.c_transforms as CV # 图像转化算子\n",
    "\n",
    "# mindspore.common\n",
    "\n",
    "from mindspore.common import dtype as mstype # 数据形态转换\n",
    "\n",
    "from mindspore.common.initializer import Normal # 参数初始化\n",
    "\n",
    "# mindspore.nn\n",
    "\n",
    "import mindspore.nn as nn # 各类网络层都在nn里面\n",
    "\n",
    "from mindspore.nn.metrics import Accuracy # 测试模型用\n",
    "\n",
    "from mindspore import Model # 承载网络结构\n",
    "\n",
    "# os模块处理数据路径用\n",
    "\n",
    "import os\n",
    "\n",
    "# numpy\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_path, batch_size=32):\n",
    "    \"\"\" \n",
    "    数据预处理与批量输出的函数\n",
    "    \n",
    "    Args:\n",
    "        data_path: 数据路径\n",
    "        batch_size: 批量大小\n",
    "    \"\"\"\n",
    "    # 定义数据集\n",
    "    data = ds.MnistDataset(data_path)\n",
    "    \n",
    "    # 打乱数据集\n",
    "    data = data.shuffle(buffer_size=10000)\n",
    "    \n",
    "    # 数据标准化参数\n",
    "    # MNIST数据集的 mean = 33.3285，std = 78.5655\n",
    "    mean, std = 33.3285, 78.5655 \n",
    "\n",
    "    # 定义算子\n",
    "    nml_op = lambda x : np.float32((x-mean)/std) # 数据标准化，image = (image-mean)/std\n",
    "    hwc2chw_op = CV.HWC2CHW() # 通道前移（为配适网络，CHW的格式可最佳发挥昇腾芯片算力）\n",
    "    type_cast_op = C.TypeCast(mstype.int32) # 原始数据的标签是unint，计算损失需要int\n",
    "\n",
    "    # 算子运算\n",
    "    data = data.map(operations=type_cast_op, input_columns='label')\n",
    "    data = data.map(operations=nml_op, input_columns='image')\n",
    "    data = data.map(operations=hwc2chw_op, input_columns='image')\n",
    "\n",
    "    # 批处理\n",
    "    data = data.batch(batch_size)\n",
    "    \n",
    "    # 重复\n",
    "    data = data.repeat(1)\n",
    "\n",
    "    return data    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考LeNet网络结构，构建网络：\n",
    "\n",
    "LeNet-5出自论文《Gradient-Based Learning Applied to Document Recognition》，原本是一种用于手写体字符识别的非常高效的卷积神经网络，包含了深度学习的基本模块：卷积层，池化层，全连接层。\n",
    "\n",
    "本实验将参考LeNet论文，建立以下网络：\n",
    "\n",
    "![](media/b235602473266272a05e66bf7481bd4a.png)\n",
    "\n",
    "INPUT（输入层） ：输入28∗28的图片。\n",
    "\n",
    "C1（卷积层）：选取6个5∗5卷积核(不包含偏置)，得到6个特征图，每个特征图的一个边为28−5+1=24。\n",
    "\n",
    "S2（池化层）：池化层是一个下采样层，输出12∗12∗6的特征图。\n",
    "\n",
    "C3（卷积层）：选取16个大小为5∗5卷积核，得到特征图大小为8∗8∗16。\n",
    "\n",
    "S4（池化层）：窗口大小为2∗2，输出4∗4∗16的特征图。\n",
    "\n",
    "F5（全连接层）：120个神经元。\n",
    "\n",
    "F6（全连接层）：84个神经元。\n",
    "\n",
    "OUTPUT（输出层）：10个神经元，10分类问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Cell):\n",
    "    \n",
    "    # 定义算子\n",
    "    def __init__(self, num_class=10, num_channel=1):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # 卷积层\n",
    "        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc1 = nn.Dense(4 * 4 * 16, 120, weight_init=Normal(0.02))\n",
    "        self.fc2 = nn.Dense(120, 84, weight_init=Normal(0.02))\n",
    "        self.fc3 = nn.Dense(84, num_class, weight_init=Normal(0.02))\n",
    "        \n",
    "        # 激活函数\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # 最大池化层\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 网络展开\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    # 建构网络\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join('./data/data-MINST/train') # 训练集路径\n",
    "train_data = create_dataset(train_path) # 定义训练数据集\n",
    "\n",
    "test_path = os.path.join('./data/data-MINST/test') # 测试集路径\n",
    "test_data = create_dataset(test_path) # 定义测试数据集 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络\n",
    "net = LeNet5()\n",
    "\n",
    "# 损失函数\n",
    "net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "\n",
    "# 优化器\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "net_opt = nn.Momentum(net.trainable_params(), lr, momentum)\n",
    "\n",
    "# 模型\n",
    "model = Model(net, net_loss, net_opt, metrics={'accuracy': Accuracy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(3, train_data) # 训练3个epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(test_data) # 测试网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=os.path.join('data', 'test')\n",
    "\n",
    "ds_test_demo = create_dataset(test_path, batch_size=1)\n",
    "\n",
    "for i, dic in enumerate(ds_test_demo.create_dict_iterator()):\n",
    "    input_img = dic['image']\n",
    "    output = model.predict(input_img)\n",
    "    predict = np.argmax(output.asnumpy(),axis=1)[0]\n",
    "    if i>9:\n",
    "        break\n",
    "    print('True: %s, Predicted: %s'%(dic['label'], predict)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the String is: 42\n",
      "\"  WELCOME TO THE MACHINE LEARNING LAB ! \"\n",
      "\"  Welcome To The Machine Learning Lab ! \"\n",
      "Welcome to the Machine Learning lab !\n"
     ]
    }
   ],
   "source": [
    "source_string = input()\n",
    "# \"Welcome to the Machine Learning lab !\"\n",
    "print(\"Length of the String is:\", len(source_string))\n",
    "upper_str=source_string.upper()\n",
    "print(upper_str)\n",
    "capitalize_str=source_string.title()\n",
    "print(capitalize_str)\n",
    "str = \"  Welcome to the Machine Learning lab ! \"\n",
    "print(str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "Machine learning is now capable of far more extensive tasks\n",
      "['Machine', 'learning', 'is', 'now', 'capable', 'of', 'far', 'more', 'complex', 'tasks']\n"
     ]
    }
   ],
   "source": [
    "source_string ='Machine learning is now capable of far more complex tasks'\n",
    "print(source_string.find('far'))\n",
    "print(source_string.replace(\"complex\",\"extensive\"))\n",
    "str_list = source_string.split(\" \")\n",
    "print(str_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
